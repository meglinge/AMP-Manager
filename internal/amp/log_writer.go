package amp

import (
	"database/sql"
	"io"
	"sync"
	"time"

	log "github.com/sirupsen/logrus"
)

// LogEntryStatus 日志条目状态
type LogEntryStatus string

const (
	LogEntryStatusPending LogEntryStatus = "pending"
	LogEntryStatusSuccess LogEntryStatus = "success"
	LogEntryStatusError   LogEntryStatus = "error"
)

// LogEntry 日志条目，用于写入数据库
type LogEntry struct {
	ID                       string
	CreatedAt                time.Time
	UpdatedAt                *time.Time
	Status                   LogEntryStatus
	UserID                   string
	APIKeyID                 string
	OriginalModel            *string
	MappedModel              *string
	Provider                 *string
	ChannelID                *string
	Endpoint                 *string
	Method                   string
	Path                     string
	StatusCode               int
	LatencyMs                int64
	IsStreaming              bool
	InputTokens              *int
	OutputTokens             *int
	CacheReadInputTokens     *int
	CacheCreationInputTokens *int
	ErrorType                *string
	RequestID                *string
}

// LogWriter 异步批量日志写入器
type LogWriter struct {
	db          *sql.DB
	entryChan   chan LogEntry
	batchSize   int
	flushInterval time.Duration
	wg          sync.WaitGroup
	stopChan    chan struct{}
	stopped     bool
	mu          sync.Mutex
}

// NewLogWriter 创建日志写入器
func NewLogWriter(db *sql.DB, bufferSize, batchSize int, flushInterval time.Duration) *LogWriter {
	w := &LogWriter{
		db:            db,
		entryChan:     make(chan LogEntry, bufferSize),
		batchSize:     batchSize,
		flushInterval: flushInterval,
		stopChan:      make(chan struct{}),
	}
	w.wg.Add(1)
	go w.run()
	return w
}

// Write 异步写入日志（非阻塞）
func (w *LogWriter) Write(entry LogEntry) bool {
	w.mu.Lock()
	if w.stopped {
		w.mu.Unlock()
		return false
	}
	w.mu.Unlock()

	select {
	case w.entryChan <- entry:
		return true
	default:
		log.Warn("log writer: queue full, dropping entry")
		return false
	}
}

// WritePendingFromTrace 同步写入 pending 状态的日志记录
// 使用 trace.RequestID 作为数据库 ID，以便后续 UPDATE
func (w *LogWriter) WritePendingFromTrace(trace *RequestTrace) bool {
	if trace == nil || trace.RequestID == "" {
		return false
	}

	snapshot := trace.Clone()

	// 构建可选字段
	var originalModel, mappedModel, provider, channelID, endpoint *string
	if snapshot.OriginalModel != "" {
		originalModel = &snapshot.OriginalModel
	}
	if snapshot.MappedModel != "" {
		mappedModel = &snapshot.MappedModel
	}
	if snapshot.Provider != "" {
		provider = &snapshot.Provider
	}
	if snapshot.ChannelID != "" {
		channelID = &snapshot.ChannelID
	}
	if snapshot.Endpoint != "" {
		endpoint = &snapshot.Endpoint
	}

	// 同步写入数据库（pending 记录需要立即可见）
	_, err := w.db.Exec(`
		INSERT INTO request_logs (
			id, created_at, status, user_id, api_key_id, original_model, mapped_model,
			provider, channel_id, endpoint, method, path, status_code, latency_ms, is_streaming
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`,
		snapshot.RequestID, // 使用 RequestID 作为数据库 ID
		snapshot.StartTime.Format(time.RFC3339),
		LogEntryStatusPending,
		snapshot.UserID,
		snapshot.APIKeyID,
		originalModel,
		mappedModel,
		provider,
		channelID,
		endpoint,
		snapshot.Method,
		snapshot.Path,
		0, // pending 时 status_code 为 0
		0, // pending 时 latency_ms 为 0
		0, // pending 时 is_streaming 为 0
	)

	if err != nil {
		log.Errorf("log writer: failed to insert pending entry: %v", err)
		return false
	}

	log.Debugf("log writer: inserted pending request %s", snapshot.RequestID)
	return true
}

// UpdateFromTrace 更新已存在的 pending 记录为完成状态
func (w *LogWriter) UpdateFromTrace(trace *RequestTrace) bool {
	if trace == nil || trace.RequestID == "" {
		return false
	}

	snapshot := trace.Clone()

	// 确定最终状态
	status := LogEntryStatusSuccess
	if snapshot.ErrorType != "" || snapshot.StatusCode >= 400 {
		status = LogEntryStatusError
	}

	now := time.Now()
	isStreaming := 0
	if snapshot.IsStreaming {
		isStreaming = 1
	}

	// 构建可选字段
	var originalModel, mappedModel, provider, channelID, endpoint, errorType *string
	if snapshot.OriginalModel != "" {
		originalModel = &snapshot.OriginalModel
	}
	if snapshot.MappedModel != "" {
		mappedModel = &snapshot.MappedModel
	}
	if snapshot.Provider != "" {
		provider = &snapshot.Provider
	}
	if snapshot.ChannelID != "" {
		channelID = &snapshot.ChannelID
	}
	if snapshot.Endpoint != "" {
		endpoint = &snapshot.Endpoint
	}
	if snapshot.ErrorType != "" {
		errorType = &snapshot.ErrorType
	}

	// 同步更新数据库
	result, err := w.db.Exec(`
		UPDATE request_logs SET
			updated_at = ?,
			status = ?,
			original_model = COALESCE(?, original_model),
			mapped_model = COALESCE(?, mapped_model),
			provider = COALESCE(?, provider),
			channel_id = COALESCE(?, channel_id),
			endpoint = COALESCE(?, endpoint),
			status_code = ?,
			latency_ms = ?,
			is_streaming = ?,
			input_tokens = ?,
			output_tokens = ?,
			cache_read_input_tokens = ?,
			cache_creation_input_tokens = ?,
			error_type = ?
		WHERE id = ?
	`,
		now.Format(time.RFC3339),
		status,
		originalModel,
		mappedModel,
		provider,
		channelID,
		endpoint,
		snapshot.StatusCode,
		snapshot.LatencyMs,
		isStreaming,
		snapshot.InputTokens,
		snapshot.OutputTokens,
		snapshot.CacheReadInputTokens,
		snapshot.CacheCreationInputTokens,
		errorType,
		snapshot.RequestID,
	)

	if err != nil {
		log.Errorf("log writer: failed to update entry %s: %v", snapshot.RequestID, err)
		return false
	}

	rowsAffected, _ := result.RowsAffected()
	if rowsAffected == 0 {
		// pending 记录不存在，fallback 到 INSERT
		log.Warnf("log writer: pending record not found for %s, inserting new", snapshot.RequestID)
		return w.insertComplete(trace)
	}

	log.Debugf("log writer: updated request %s to status %s", snapshot.RequestID, status)
	return true
}

// insertComplete 直接插入完整记录（fallback 用于 pending 记录丢失的情况）
func (w *LogWriter) insertComplete(trace *RequestTrace) bool {
	snapshot := trace.Clone()

	status := LogEntryStatusSuccess
	if snapshot.ErrorType != "" || snapshot.StatusCode >= 400 {
		status = LogEntryStatusError
	}

	now := time.Now()
	isStreaming := 0
	if snapshot.IsStreaming {
		isStreaming = 1
	}

	var originalModel, mappedModel, provider, channelID, endpoint, errorType *string
	if snapshot.OriginalModel != "" {
		originalModel = &snapshot.OriginalModel
	}
	if snapshot.MappedModel != "" {
		mappedModel = &snapshot.MappedModel
	}
	if snapshot.Provider != "" {
		provider = &snapshot.Provider
	}
	if snapshot.ChannelID != "" {
		channelID = &snapshot.ChannelID
	}
	if snapshot.Endpoint != "" {
		endpoint = &snapshot.Endpoint
	}
	if snapshot.ErrorType != "" {
		errorType = &snapshot.ErrorType
	}

	_, err := w.db.Exec(`
		INSERT INTO request_logs (
			id, created_at, updated_at, status, user_id, api_key_id, original_model, mapped_model,
			provider, channel_id, endpoint, method, path, status_code, latency_ms,
			is_streaming, input_tokens, output_tokens, cache_read_input_tokens,
			cache_creation_input_tokens, error_type
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`,
		snapshot.RequestID,
		snapshot.StartTime.Format(time.RFC3339),
		now.Format(time.RFC3339),
		status,
		snapshot.UserID,
		snapshot.APIKeyID,
		originalModel,
		mappedModel,
		provider,
		channelID,
		endpoint,
		snapshot.Method,
		snapshot.Path,
		snapshot.StatusCode,
		snapshot.LatencyMs,
		isStreaming,
		snapshot.InputTokens,
		snapshot.OutputTokens,
		snapshot.CacheReadInputTokens,
		snapshot.CacheCreationInputTokens,
		errorType,
	)

	if err != nil {
		log.Errorf("log writer: failed to insert complete entry: %v", err)
		return false
	}
	return true
}

// WriteFromTrace 直接写入完整日志记录（用于非 pending 工作流，如非模型调用请求）
func (w *LogWriter) WriteFromTrace(trace *RequestTrace) bool {
	if trace == nil || trace.RequestID == "" {
		return false
	}
	return w.insertComplete(trace)
}

// Stop 停止写入器并刷新剩余日志
func (w *LogWriter) Stop() {
	w.mu.Lock()
	if w.stopped {
		w.mu.Unlock()
		return
	}
	w.stopped = true
	w.mu.Unlock()

	close(w.stopChan)
	w.wg.Wait()
}

// run 后台运行的写入循环
func (w *LogWriter) run() {
	defer w.wg.Done()

	batch := make([]LogEntry, 0, w.batchSize)
	ticker := time.NewTicker(w.flushInterval)
	defer ticker.Stop()

	for {
		select {
		case entry := <-w.entryChan:
			batch = append(batch, entry)
			if len(batch) >= w.batchSize {
				w.flush(batch)
				batch = batch[:0]
			}
		case <-ticker.C:
			if len(batch) > 0 {
				w.flush(batch)
				batch = batch[:0]
			}
		case <-w.stopChan:
			// 处理剩余的日志
			close(w.entryChan)
			for entry := range w.entryChan {
				batch = append(batch, entry)
			}
			if len(batch) > 0 {
				w.flush(batch)
			}
			return
		}
	}
}

// flush 批量写入数据库
func (w *LogWriter) flush(entries []LogEntry) {
	if len(entries) == 0 {
		return
	}

	tx, err := w.db.Begin()
	if err != nil {
		log.Errorf("log writer: failed to begin transaction: %v", err)
		return
	}

	stmt, err := tx.Prepare(`
		INSERT INTO request_logs (
			id, created_at, updated_at, status, user_id, api_key_id, original_model, mapped_model,
			provider, channel_id, endpoint, method, path, status_code, latency_ms,
			is_streaming, input_tokens, output_tokens, cache_read_input_tokens,
			cache_creation_input_tokens, error_type
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`)
	if err != nil {
		log.Errorf("log writer: failed to prepare statement: %v", err)
		tx.Rollback()
		return
	}
	defer stmt.Close()

	for _, e := range entries {
		isStreaming := 0
		if e.IsStreaming {
			isStreaming = 1
		}

		_, err := stmt.Exec(
			e.ID, e.CreatedAt.Format(time.RFC3339), e.CreatedAt.Format(time.RFC3339), LogEntryStatusSuccess, e.UserID, e.APIKeyID, e.OriginalModel, e.MappedModel,
			e.Provider, e.ChannelID, e.Endpoint, e.Method, e.Path, e.StatusCode, e.LatencyMs,
			isStreaming, e.InputTokens, e.OutputTokens, e.CacheReadInputTokens,
			e.CacheCreationInputTokens, e.ErrorType,
		)
		if err != nil {
			log.Errorf("log writer: failed to insert entry: %v", err)
		}
	}

	if err := tx.Commit(); err != nil {
		log.Errorf("log writer: failed to commit transaction: %v", err)
		tx.Rollback()
		return
	}

	log.Debugf("log writer: flushed %d entries", len(entries))
}

// 全局日志写入器实例
var (
	globalLogWriter *LogWriter
	logWriterOnce   sync.Once
)

// InitLogWriter 初始化全局日志写入器
func InitLogWriter(db *sql.DB) {
	logWriterOnce.Do(func() {
		globalLogWriter = NewLogWriter(db, 10000, 100, 200*time.Millisecond)
		log.Info("log writer: initialized")
	})
}

// GetLogWriter 获取全局日志写入器
func GetLogWriter() *LogWriter {
	return globalLogWriter
}

// StopLogWriter 停止全局日志写入器
func StopLogWriter() {
	if globalLogWriter != nil {
		globalLogWriter.Stop()
		log.Info("log writer: stopped")
	}
}

// LoggingBodyWrapper 包装响应体，在 Close 时写入日志
type LoggingBodyWrapper struct {
	io.ReadCloser
	trace      *RequestTrace
	statusCode int
	once       sync.Once
}

// NewLoggingBodyWrapper 创建日志包装器
func NewLoggingBodyWrapper(body io.ReadCloser, trace *RequestTrace, statusCode int) *LoggingBodyWrapper {
	return &LoggingBodyWrapper{
		ReadCloser: body,
		trace:      trace,
		statusCode: statusCode,
	}
}

// Close 关闭并更新日志记录
func (w *LoggingBodyWrapper) Close() error {
	err := w.ReadCloser.Close()
	w.once.Do(func() {
		if w.trace != nil {
			w.trace.SetResponse(w.statusCode)
			if writer := GetLogWriter(); writer != nil {
				writer.UpdateFromTrace(w.trace)
			}
		}
	})
	return err
}
