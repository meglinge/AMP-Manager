package repository

import (
	"database/sql"
	"fmt"
	"strings"
	"time"

	"ampmanager/internal/database"
	"ampmanager/internal/model"
)

type RequestLogRepository struct{}

func NewRequestLogRepository() *RequestLogRepository {
	return &RequestLogRepository{}
}

// ListParams 查询参数
type ListParams struct {
	UserID      string
	APIKeyID    string
	Model       string
	StatusCode  *int
	IsStreaming *bool
	From        *time.Time
	To          *time.Time
	Page        int
	PageSize    int
}

// List 查询请求日志列表
func (r *RequestLogRepository) List(params ListParams) ([]model.RequestLog, int64, error) {
	db := database.GetDB()

	// 构建 WHERE 条件（使用 r. 前缀避免 JOIN 时的歧义）
	conditions := []string{"1=1"}
	args := []interface{}{}

	if params.UserID != "" {
		conditions = append(conditions, "r.user_id = ?")
		args = append(args, params.UserID)
	}
	if params.APIKeyID != "" {
		conditions = append(conditions, "r.api_key_id = ?")
		args = append(args, params.APIKeyID)
	}
	if params.Model != "" {
		conditions = append(conditions, "(r.original_model = ? OR r.mapped_model = ?)")
		args = append(args, params.Model, params.Model)
	}
	if params.StatusCode != nil {
		conditions = append(conditions, "r.status_code = ?")
		args = append(args, *params.StatusCode)
	}
	if params.IsStreaming != nil {
		val := 0
		if *params.IsStreaming {
			val = 1
		}
		conditions = append(conditions, "r.is_streaming = ?")
		args = append(args, val)
	}
	if params.From != nil {
		conditions = append(conditions, "r.created_at >= ?")
		args = append(args, params.From.UTC().Format(time.RFC3339))
	}
	if params.To != nil {
		conditions = append(conditions, "r.created_at <= ?")
		args = append(args, params.To.UTC().Format(time.RFC3339))
	}

	whereClause := strings.Join(conditions, " AND ")

	// 查询总数
	var total int64
	countQuery := fmt.Sprintf("SELECT COUNT(*) FROM request_logs r WHERE %s", whereClause)
	if err := db.QueryRow(countQuery, args...).Scan(&total); err != nil {
		return nil, 0, err
	}

	// 分页
	if params.Page < 1 {
		params.Page = 1
	}
	if params.PageSize < 1 {
		params.PageSize = 20
	}
	if params.PageSize > 100 {
		params.PageSize = 100
	}
	offset := (params.Page - 1) * params.PageSize

	// 查询数据
	query := fmt.Sprintf(`
		SELECT r.id, r.created_at, r.updated_at, r.status, r.user_id, u.username, r.api_key_id, r.original_model, r.mapped_model,
		       r.provider, r.channel_id, r.endpoint, r.method, r.path, r.status_code, r.latency_ms,
		       r.is_streaming, r.input_tokens, r.output_tokens, r.cache_read_input_tokens,
		       r.cache_creation_input_tokens, r.error_type, r.request_id, r.cost_micros, r.cost_usd, r.pricing_model, r.thinking_level,
		       COALESCE(SUBSTR(r.response_text, 1, 200), SUBSTR(d.response_body, 1, 200)) as output_preview
		FROM request_logs r
		LEFT JOIN users u ON r.user_id = u.id
		LEFT JOIN request_log_details d ON r.id = d.request_id
		WHERE %s
		ORDER BY r.created_at DESC
		LIMIT ? OFFSET ?
	`, whereClause)

	args = append(args, params.PageSize, offset)
	rows, err := db.Query(query, args...)
	if err != nil {
		return nil, 0, err
	}
	defer rows.Close()

	var logs []model.RequestLog
	for rows.Next() {
		var log model.RequestLog
		var createdAt time.Time
		var updatedAt sql.NullTime
		var status sql.NullString
		var isStreaming int
		var username sql.NullString
		var originalModel, mappedModel, provider, channelID, endpoint, errorType, requestID, costUsd, pricingModel, thinkingLevel, outputPreview sql.NullString
		var inputTokens, outputTokens, cacheRead, cacheCreation, costMicros sql.NullInt64

		err := rows.Scan(
			&log.ID, &createdAt, &updatedAt, &status, &log.UserID, &username, &log.APIKeyID,
			&originalModel, &mappedModel, &provider, &channelID, &endpoint,
			&log.Method, &log.Path, &log.StatusCode, &log.LatencyMs,
			&isStreaming, &inputTokens, &outputTokens, &cacheRead, &cacheCreation,
			&errorType, &requestID, &costMicros, &costUsd, &pricingModel, &thinkingLevel,
			&outputPreview,
		)
		if err != nil {
			return nil, 0, err
		}

		log.CreatedAt = createdAt.Format(time.RFC3339)
		log.IsStreaming = isStreaming == 1

		if username.Valid {
			log.Username = &username.String
		}
		if updatedAt.Valid {
			formatted := updatedAt.Time.Format(time.RFC3339)
			log.UpdatedAt = &formatted
		}
		if status.Valid {
			log.Status = model.RequestLogStatus(status.String)
		} else {
			log.Status = model.RequestLogStatusSuccess // 默认为 success（兼容旧数据）
		}

		if originalModel.Valid {
			log.OriginalModel = &originalModel.String
		}
		if mappedModel.Valid {
			log.MappedModel = &mappedModel.String
		}
		if provider.Valid {
			log.Provider = &provider.String
		}
		if channelID.Valid {
			log.ChannelID = &channelID.String
		}
		if endpoint.Valid {
			log.Endpoint = &endpoint.String
		}
		if errorType.Valid {
			log.ErrorType = &errorType.String
		}
		if requestID.Valid {
			log.RequestID = &requestID.String
		}
		if inputTokens.Valid {
			v := int(inputTokens.Int64)
			log.InputTokens = &v
		}
		if outputTokens.Valid {
			v := int(outputTokens.Int64)
			log.OutputTokens = &v
		}
		if cacheRead.Valid {
			v := int(cacheRead.Int64)
			log.CacheReadInputTokens = &v
		}
		if cacheCreation.Valid {
			v := int(cacheCreation.Int64)
			log.CacheCreationInputTokens = &v
		}
		if costMicros.Valid {
			log.CostMicros = &costMicros.Int64
		}
		if costUsd.Valid {
			log.CostUsd = &costUsd.String
		}
		if pricingModel.Valid {
			log.PricingModel = &pricingModel.String
		}
		if thinkingLevel.Valid {
			log.ThinkingLevel = &thinkingLevel.String
		}
		if outputPreview.Valid {
			log.OutputPreview = &outputPreview.String
		}

		logs = append(logs, log)
	}

	return logs, total, rows.Err()
}

// GetUsageSummary 获取用量统计
// userID 为 nil 或空字符串时查询所有用户
func (r *RequestLogRepository) GetUsageSummary(userID *string, from, to *time.Time, groupBy string) ([]model.UsageSummary, error) {
	db := database.GetDB()

	var groupColumn string
	switch groupBy {
	case "day":
		groupColumn = "substr(created_at, 1, 10)"
	case "model":
		groupColumn = "COALESCE(mapped_model, original_model, 'unknown')"
	case "apiKey":
		groupColumn = "api_key_id"
	case "user":
		groupColumn = "user_id"
	default:
		groupColumn = "date(created_at)"
	}

	conditions := []string{"1=1"}
	args := []interface{}{}

	if userID != nil && *userID != "" {
		conditions = append(conditions, "user_id = ?")
		args = append(args, *userID)
	}

	if from != nil {
		conditions = append(conditions, "created_at >= ?")
		args = append(args, from.UTC().Format(time.RFC3339))
	}
	if to != nil {
		conditions = append(conditions, "created_at <= ?")
		args = append(args, to.UTC().Format(time.RFC3339))
	}

	whereClause := strings.Join(conditions, " AND ")

	query := fmt.Sprintf(`
		SELECT 
			%s as group_key,
			COALESCE(SUM(input_tokens), 0) as input_tokens_sum,
			COALESCE(SUM(output_tokens), 0) as output_tokens_sum,
			COALESCE(SUM(cache_read_input_tokens), 0) as cache_read_sum,
			COALESCE(SUM(cache_creation_input_tokens), 0) as cache_creation_sum,
			COUNT(*) as request_count,
			SUM(CASE WHEN status_code >= 400 THEN 1 ELSE 0 END) as error_count,
			COALESCE(SUM(cost_micros), 0) as cost_micros_sum
		FROM request_logs
		WHERE %s
		GROUP BY %s
		ORDER BY %s DESC
		LIMIT 100
	`, groupColumn, whereClause, groupColumn, groupColumn)

	rows, err := db.Query(query, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var summaries []model.UsageSummary
	for rows.Next() {
		var s model.UsageSummary
		err := rows.Scan(
			&s.GroupKey,
			&s.InputTokensSum,
			&s.OutputTokensSum,
			&s.CacheReadInputTokensSum,
			&s.CacheCreationInputTokensSum,
			&s.RequestCount,
			&s.ErrorCount,
			&s.CostMicrosSum,
		)
		if err != nil {
			return nil, err
		}
		// 转换为 USD 字符串
		s.CostUsdSum = fmt.Sprintf("%.6f", float64(s.CostMicrosSum)/1_000_000)
		summaries = append(summaries, s)
	}

	return summaries, rows.Err()
}

// GetDistinctModels 获取使用过的模型列表
func (r *RequestLogRepository) GetDistinctModels() ([]string, error) {
	db := database.GetDB()

	query := `
		SELECT DISTINCT COALESCE(mapped_model, original_model) as model
		FROM request_logs
		WHERE mapped_model IS NOT NULL OR original_model IS NOT NULL
		ORDER BY model
		LIMIT 100
	`

	rows, err := db.Query(query)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var models []string
	for rows.Next() {
		var m string
		if err := rows.Scan(&m); err != nil {
			return nil, err
		}
		models = append(models, m)
	}

	return models, rows.Err()
}

// DashboardPeriodStats 仪表盘时段统计
type DashboardPeriodStats struct {
	RequestCount    int64
	InputTokensSum  int64
	OutputTokensSum int64
	CostMicrosSum   int64
	ErrorCount      int64
}

// DashboardTopModel 仪表盘热门模型
type DashboardTopModel struct {
	Model        string
	RequestCount int64
	CostMicros   int64
}

// DashboardDailyTrend 仪表盘每日趋势
type DashboardDailyTrend struct {
	Date       string
	CostMicros int64
	Requests   int64
}

// DashboardCacheHitRate 按提供商分类的缓存命中率
type DashboardCacheHitRate struct {
	Provider            string
	TotalInputTokens    int64
	CacheReadTokens     int64
	CacheCreationTokens int64
	RequestCount        int64
	HitRate             float64
}

// GetDashboardStats 获取仪表盘统计数据
func (r *RequestLogRepository) GetDashboardStats(userID string) (today, week, month DashboardPeriodStats, topModels []DashboardTopModel, dailyTrend []DashboardDailyTrend, err error) {
	db := database.GetDB()
	now := time.Now().UTC()
	todayStart := time.Date(now.Year(), now.Month(), now.Day(), 0, 0, 0, 0, time.UTC)
	weekStart := todayStart.AddDate(0, 0, -7)
	monthStart := todayStart.AddDate(0, 0, -30)

	queryPeriod := func(from time.Time) (DashboardPeriodStats, error) {
		var s DashboardPeriodStats
		err := db.QueryRow(`
			SELECT COUNT(*),
			       COALESCE(SUM(input_tokens), 0),
			       COALESCE(SUM(output_tokens), 0),
			       COALESCE(SUM(cost_micros), 0),
			       SUM(CASE WHEN status_code >= 400 THEN 1 ELSE 0 END)
			FROM request_logs WHERE user_id = ? AND created_at >= ?
		`, userID, from.UTC().Format(time.RFC3339)).Scan(&s.RequestCount, &s.InputTokensSum, &s.OutputTokensSum, &s.CostMicrosSum, &s.ErrorCount)
		return s, err
	}

	today, err = queryPeriod(todayStart)
	if err != nil {
		return
	}
	week, err = queryPeriod(weekStart)
	if err != nil {
		return
	}
	month, err = queryPeriod(monthStart)
	if err != nil {
		return
	}

	rows, err := db.Query(`
		SELECT COALESCE(mapped_model, original_model, 'unknown') as model,
		       COUNT(*) as cnt,
		       COALESCE(SUM(cost_micros), 0) as cost
		FROM request_logs
		WHERE user_id = ? AND created_at >= ?
		GROUP BY model
		ORDER BY cnt DESC
		LIMIT 5
	`, userID, monthStart.Format(time.RFC3339))
	if err != nil {
		return
	}
	defer rows.Close()
	for rows.Next() {
		var m DashboardTopModel
		if err = rows.Scan(&m.Model, &m.RequestCount, &m.CostMicros); err != nil {
			return
		}
		topModels = append(topModels, m)
	}
	if err = rows.Err(); err != nil {
		return
	}

	rows2, err := db.Query(`
		SELECT substr(created_at, 1, 10) as day,
		       COALESCE(SUM(cost_micros), 0) as cost,
		       COUNT(*) as cnt
		FROM request_logs
		WHERE user_id = ? AND created_at >= ?
		GROUP BY day
		ORDER BY day ASC
	`, userID, todayStart.AddDate(0, 0, -13).Format(time.RFC3339))
	if err != nil {
		return
	}
	defer rows2.Close()
	for rows2.Next() {
		var d DashboardDailyTrend
		if err = rows2.Scan(&d.Date, &d.CostMicros, &d.Requests); err != nil {
			return
		}
		dailyTrend = append(dailyTrend, d)
	}
	err = rows2.Err()
	return
}

// GetCacheHitRateByProvider 按提供商分类获取缓存命中率（30天）
func (r *RequestLogRepository) GetCacheHitRateByProvider(userID string) ([]DashboardCacheHitRate, error) {
	db := database.GetDB()
	monthStart := time.Now().UTC().AddDate(0, 0, -30)

	query := `
		SELECT provider, total_input, cache_read, cache_creation, req_count FROM (
			SELECT 
				CASE
					WHEN LOWER(COALESCE(mapped_model, original_model, '')) LIKE 'claude%' THEN 'Claude'
					WHEN LOWER(COALESCE(mapped_model, original_model, '')) LIKE 'gpt%' 
					  OR LOWER(COALESCE(mapped_model, original_model, '')) LIKE 'o1%'
					  OR LOWER(COALESCE(mapped_model, original_model, '')) LIKE 'o3%'
					  OR LOWER(COALESCE(mapped_model, original_model, '')) LIKE 'o4%'
					  OR LOWER(COALESCE(mapped_model, original_model, '')) LIKE 'chatgpt%' THEN 'OpenAI'
					WHEN LOWER(COALESCE(mapped_model, original_model, '')) LIKE 'gemini%' THEN 'Gemini'
					ELSE 'Other'
				END as provider,
				COALESCE(SUM(input_tokens), 0) as total_input,
				COALESCE(SUM(cache_read_input_tokens), 0) as cache_read,
				COALESCE(SUM(cache_creation_input_tokens), 0) as cache_creation,
				COUNT(*) as req_count
			FROM request_logs
			WHERE user_id = ? AND created_at >= ?
			GROUP BY provider
		) WHERE provider IN ('Claude', 'OpenAI', 'Gemini')
		ORDER BY req_count DESC
	`

	rows, err := db.Query(query, userID, monthStart.Format(time.RFC3339))
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var results []DashboardCacheHitRate
	for rows.Next() {
		var r DashboardCacheHitRate
		if err := rows.Scan(&r.Provider, &r.TotalInputTokens, &r.CacheReadTokens, &r.CacheCreationTokens, &r.RequestCount); err != nil {
			return nil, err
		}
		totalRelevant := r.TotalInputTokens + r.CacheReadTokens
		if totalRelevant > 0 {
			r.HitRate = float64(r.CacheReadTokens) / float64(totalRelevant) * 100
		}
		results = append(results, r)
	}
	return results, rows.Err()
}

// GetByID 获取单条日志
func (r *RequestLogRepository) GetByID(id string) (*model.RequestLog, error) {
	db := database.GetDB()

	var log model.RequestLog
	var createdAt time.Time
	var updatedAt sql.NullTime
	var status sql.NullString
	var isStreaming int
	var originalModel, mappedModel, provider, channelID, endpoint, errorType, requestID, costUsd, pricingModel, thinkingLevel sql.NullString
	var inputTokens, outputTokens, cacheRead, cacheCreation, costMicros sql.NullInt64

	err := db.QueryRow(`
		SELECT id, created_at, updated_at, status, user_id, api_key_id, original_model, mapped_model,
		       provider, channel_id, endpoint, method, path, status_code, latency_ms,
		       is_streaming, input_tokens, output_tokens, cache_read_input_tokens,
		       cache_creation_input_tokens, error_type, request_id, cost_micros, cost_usd, pricing_model, thinking_level
		FROM request_logs WHERE id = ?
	`, id).Scan(
		&log.ID, &createdAt, &updatedAt, &status, &log.UserID, &log.APIKeyID,
		&originalModel, &mappedModel, &provider, &channelID, &endpoint,
		&log.Method, &log.Path, &log.StatusCode, &log.LatencyMs,
		&isStreaming, &inputTokens, &outputTokens, &cacheRead, &cacheCreation,
		&errorType, &requestID, &costMicros, &costUsd, &pricingModel, &thinkingLevel,
	)

	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, err
	}

	log.CreatedAt = createdAt.Format(time.RFC3339)
	log.IsStreaming = isStreaming == 1

	if updatedAt.Valid {
		formatted := updatedAt.Time.Format(time.RFC3339)
		log.UpdatedAt = &formatted
	}
	if status.Valid {
		log.Status = model.RequestLogStatus(status.String)
	} else {
		log.Status = model.RequestLogStatusSuccess
	}

	if originalModel.Valid {
		log.OriginalModel = &originalModel.String
	}
	if mappedModel.Valid {
		log.MappedModel = &mappedModel.String
	}
	if provider.Valid {
		log.Provider = &provider.String
	}
	if channelID.Valid {
		log.ChannelID = &channelID.String
	}
	if endpoint.Valid {
		log.Endpoint = &endpoint.String
	}
	if errorType.Valid {
		log.ErrorType = &errorType.String
	}
	if requestID.Valid {
		log.RequestID = &requestID.String
	}
	if inputTokens.Valid {
		v := int(inputTokens.Int64)
		log.InputTokens = &v
	}
	if outputTokens.Valid {
		v := int(outputTokens.Int64)
		log.OutputTokens = &v
	}
	if cacheRead.Valid {
		v := int(cacheRead.Int64)
		log.CacheReadInputTokens = &v
	}
	if cacheCreation.Valid {
		v := int(cacheCreation.Int64)
		log.CacheCreationInputTokens = &v
	}
	if costMicros.Valid {
		log.CostMicros = &costMicros.Int64
	}
	if costUsd.Valid {
		log.CostUsd = &costUsd.String
	}
	if pricingModel.Valid {
		log.PricingModel = &pricingModel.String
	}
	if thinkingLevel.Valid {
		log.ThinkingLevel = &thinkingLevel.String
	}

	return &log, nil
}
